{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:33.738729Z",
     "iopub.status.busy": "2020-12-01T07:12:33.737920Z",
     "iopub.status.idle": "2020-12-01T07:12:41.423090Z",
     "shell.execute_reply": "2020-12-01T07:12:41.422361Z"
    },
    "papermill": {
     "duration": 7.724082,
     "end_time": "2020-12-01T07:12:41.423253",
     "exception": false,
     "start_time": "2020-12-01T07:12:33.699171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Image Data Generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Kaggle dataset\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "# Pre-trained\n",
    "from tensorflow.keras.applications import DenseNet201, Xception\n",
    "\n",
    "# Keras components\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.layers import Input, Reshape, Concatenate, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D, GlobalAvgPool2D\n",
    "from keras.layers import Subtract, Multiply\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# # Experiment tracking using Weights and Biases\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "\n",
    "# for error\n",
    "# https://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:41.576687Z",
     "iopub.status.busy": "2020-12-01T07:12:41.495169Z",
     "iopub.status.idle": "2020-12-01T07:12:45.668729Z",
     "shell.execute_reply": "2020-12-01T07:12:45.667989Z"
    },
    "papermill": {
     "duration": 4.22004,
     "end_time": "2020-12-01T07:12:45.668851",
     "exception": false,
     "start_time": "2020-12-01T07:12:41.448811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# TPU setting\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "print(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024701,
     "end_time": "2020-12-01T07:12:45.718888",
     "exception": false,
     "start_time": "2020-12-01T07:12:45.694187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pipeline: Training All Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:45.781722Z",
     "iopub.status.busy": "2020-12-01T07:12:45.780925Z",
     "iopub.status.idle": "2020-12-01T07:12:46.314786Z",
     "shell.execute_reply": "2020-12-01T07:12:46.313963Z"
    },
    "papermill": {
     "duration": 0.569623,
     "end_time": "2020-12-01T07:12:46.314937",
     "exception": false,
     "start_time": "2020-12-01T07:12:45.745314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Images path and labels\n",
    "\n",
    "# Data access\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"product-matching-id-ndsc-2020\")\n",
    "\n",
    "def get_images_path_and_labels(df, path, get_label=True):\n",
    "    image1_paths = []\n",
    "    image2_paths = []\n",
    "    labels = []\n",
    "\n",
    "    image1_paths = df.image_1.apply(lambda x: '{}/{}/{}/{}'.format(GCS_DS_PATH, path, path, x)).tolist()\n",
    "    image2_paths = df.image_2.apply(lambda x: '{}/{}/{}/{}'.format(GCS_DS_PATH, path, path, x)).tolist()\n",
    "    \n",
    "    if get_label:\n",
    "        labels = df.Label.tolist()\n",
    "        return image1_paths, image2_paths, labels\n",
    "    else:\n",
    "        return image1_paths, image2_paths, [0] * len(image1_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:46.524502Z",
     "iopub.status.busy": "2020-12-01T07:12:46.523396Z",
     "iopub.status.idle": "2020-12-01T07:12:46.527032Z",
     "shell.execute_reply": "2020-12-01T07:12:46.526284Z"
    },
    "papermill": {
     "duration": 0.187034,
     "end_time": "2020-12-01T07:12:46.527154",
     "exception": false,
     "start_time": "2020-12-01T07:12:46.340120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to calculate metrics\n",
    "from keras import backend as K\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "def exponent_neg_manhattan_distance(vests):\n",
    "    ''' Helper function for the similarity estimate of the two vectors'''\n",
    "    x, y = vests\n",
    "    return K.exp(-K.sum(K.abs(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def manhattan_distance(vests):\n",
    "    ''' Helper function for the similarity estimate of the two vectors'''\n",
    "    x, y = vests\n",
    "    return K.sum(K.abs(x - y), axis=1, keepdims=True)\n",
    "\n",
    "def dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025156,
     "end_time": "2020-12-01T07:12:46.577772",
     "exception": false,
     "start_time": "2020-12-01T07:12:46.552616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:46.662751Z",
     "iopub.status.busy": "2020-12-01T07:12:46.661845Z",
     "iopub.status.idle": "2020-12-01T07:12:46.917764Z",
     "shell.execute_reply": "2020-12-01T07:12:46.918327Z"
    },
    "papermill": {
     "duration": 0.315534,
     "end_time": "2020-12-01T07:12:46.918491",
     "exception": false,
     "start_time": "2020-12-01T07:12:46.602957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 0.0005090000000000001, 0.0010080000000000002, 0.0015070000000000003, 0.0020060000000000004, 0.0025050000000000007, 0.0030040000000000006, 0.0035030000000000005, 0.004002, 0.004501000000000001, 0.005, 0.00475, 0.0045125, 0.004286875, 0.00407253125, 0.003868904687499999, 0.003675459453124999, 0.003491686480468749, 0.0033171021564453113, 0.0031512470486230455, 0.0029936846961918936, 0.0028440004613822984, 0.0027018004383131834, 0.002566710416397524, 0.0024383748955776477, 0.002316456150798765, 0.0022006333432588268, 0.0020906016760958855, 0.001986071592291091, 0.0018867680126765363, 0.0017924296120427094]\n"
     ]
    }
   ],
   "source": [
    "# Model Parameter\n",
    "# Configuration\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "IMAGE_CHANNELS = 3\n",
    "DIM = 299\n",
    "IMAGE_SIZE = (DIM, DIM)\n",
    "EMBEDDING_SIZE = 128\n",
    "COEF_SMOOTHING = 0.1\n",
    "COEF_DROPOUT = 0.01\n",
    "NUM_FOLDS = 4\n",
    "\n",
    "# CUSTOM LEARNING SCHEUDLE\n",
    "# # Xception\n",
    "# EPOCH = 15\n",
    "# SUSTAIN_EPOCHS = 1\n",
    "# LR_START = 1e-5\n",
    "# LR_MAX = 1e-3\n",
    "# LR_RAMPUP_EPOCHS = 8\n",
    "# LR_SUSTAIN_EPOCHS = 0\n",
    "# LR_STEP_DECAY = 0.8\n",
    "\n",
    "# DenseNet201\n",
    "EPOCH = 30\n",
    "SUSTAIN_EPOCHS = 1\n",
    "LR_START = 1e-5\n",
    "LR_MAX = 5e-3\n",
    "LR_RAMPUP_EPOCHS = 10\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_STEP_DECAY = 0.95\n",
    "\n",
    "# Define model and Scheduler Learning Rate\n",
    "def get_model():\n",
    "    with strategy.scope():\n",
    "        input_shape = (2, DIM, DIM, IMAGE_CHANNELS)\n",
    "        first_input = Input(input_shape)\n",
    "\n",
    "        # slice the tensor of 2 images\n",
    "        input_1 = Lambda( lambda x: tf.reshape(tf.slice( x, [0,0,0,0,0], [-1, 1, DIM, DIM, IMAGE_CHANNELS]), shape=(-1, DIM, DIM, IMAGE_CHANNELS)) )(first_input)\n",
    "        input_2 = Lambda( lambda x: tf.reshape(tf.slice( x, [0,1,0,0,0], [-1, 1, DIM, DIM, IMAGE_CHANNELS]), shape=(-1, DIM, DIM, IMAGE_CHANNELS)) )(first_input)\n",
    "        \n",
    "        # MAKE SURE THE BASE MODEL CORRECT\n",
    "        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(DIM, DIM, IMAGE_CHANNELS))\n",
    "\n",
    "        x1 = base_model(input_1)\n",
    "        x2 = base_model(input_2)\n",
    "\n",
    "#         x1 = Concatenate(axis=-1)([GlobalMaxPooling2D()(x1), GlobalAvgPool2D()(x1)]) # concatenating max pool and avg pool\n",
    "#         x2 = Concatenate(axis=-1)([GlobalMaxPooling2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "\n",
    "        x1_max = GlobalMaxPooling2D()(x1) # pooling max\n",
    "        x2_max = GlobalMaxPooling2D()(x2)\n",
    "\n",
    "        x1_avg = GlobalAvgPool2D()(x1) # pooling avg\n",
    "        x2_avg = GlobalAvgPool2D()(x2)\n",
    "        \n",
    "        x3_max = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1_max, x2_max]) # calculate cosine distance between input1 and input2\n",
    "        x4_max = Lambda(exponent_neg_manhattan_distance, output_shape=dist_output_shape)([x1_max, x2_max]) # calculate exp negative manhattan distance between input1 and input2\n",
    "        x5_max = Lambda(manhattan_distance, output_shape=dist_output_shape)([x1_max, x2_max]) # calculate manhattan distance between input1 and input2\n",
    "\n",
    "        x3_avg = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1_avg, x2_avg])\n",
    "        x4_avg = Lambda(exponent_neg_manhattan_distance, output_shape=dist_output_shape)([x1_avg, x2_avg])\n",
    "        x5_avg = Lambda(manhattan_distance, output_shape=dist_output_shape)([x1_avg, x2_avg])\n",
    "\n",
    "#         x3 = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x1, x2])\n",
    "#         x4 = Lambda(exponent_neg_manhattan_distance, output_shape=dist_output_shape)([x1, x2])\n",
    "#         x5 = Lambda(manhattan_distance, output_shape=dist_output_shape)([x1, x2])\n",
    "\n",
    "        x = Concatenate(axis=-1)([x3_max, x4_max, x5_max, x3_avg, x4_avg, x5_avg])\n",
    "    \n",
    "#         x = Dense(EMBEDDING_SIZE, activation='relu')(x)\n",
    "#         x = Dropout(COEF_DROPOUT)(x)\n",
    "        \n",
    "        out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(first_input, out)\n",
    "        model.compile(loss= tf.keras.losses.BinaryCrossentropy(label_smoothing = COEF_SMOOTHING), \n",
    "                      metrics=['acc', f1_m], optimizer= Adam(learning_rate = LR_START))\n",
    "#         model.summary()\n",
    "    return model\n",
    "\n",
    "def learning_rate_function(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//SUSTAIN_EPOCHS)\n",
    "    return lr\n",
    "    \n",
    "learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_function, verbose = True)\n",
    "\n",
    "# Plotting learning rate curve\n",
    "rng = [i for i in range(EPOCH+1)]\n",
    "y = [learning_rate_function(x) for x in rng]\n",
    "plt.plot(rng, y); \n",
    "plt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\n",
    "plt.title('Training Schedule',size=16); plt.show()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026688,
     "end_time": "2020-12-01T07:12:46.973186",
     "exception": false,
     "start_time": "2020-12-01T07:12:46.946498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preprocess Image\n",
    "Use TensorFlow Dataset for faster training time (use feature `prefetch()` and `cache()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.044946Z",
     "iopub.status.busy": "2020-12-01T07:12:47.040840Z",
     "iopub.status.idle": "2020-12-01T07:12:47.048735Z",
     "shell.execute_reply": "2020-12-01T07:12:47.047965Z"
    },
    "papermill": {
     "duration": 0.048798,
     "end_time": "2020-12-01T07:12:47.048863",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.000065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "# Data Generator using GPU\n",
    "def decode_image(filename1, filename2, label=None, image_size=(DIM, DIM)):\n",
    "    bits1 = tf.io.read_file(filename1)\n",
    "    image1 = tf.image.decode_jpeg(bits1, channels=3, try_recover_truncated=True)\n",
    "    image1 = tf.cast(image1, tf.float32) / 255.0\n",
    "    image1 = tf.image.resize(image1, image_size)\n",
    "\n",
    "    bits2 = tf.io.read_file(filename2)\n",
    "    image2 = tf.image.decode_jpeg(bits2, channels=3, try_recover_truncated=True)\n",
    "    image2 = tf.cast(image2, tf.float32) / 255.0\n",
    "    image2 = tf.image.resize(image2, image_size)\n",
    "        \n",
    "    if label is None:\n",
    "        return [image1, image2]\n",
    "    else:\n",
    "        return [image1, image2], label\n",
    "\n",
    "def get_training_dataset(df):\n",
    "    image1, image2, label = get_images_path_and_labels(df, 'training_img', get_label=True)\n",
    "    dataset = ( tf.data.Dataset.from_tensor_slices((image1, image2, label))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .cache()\n",
    "                 .repeat()\n",
    "                 .shuffle(2048)\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "              )\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(df):\n",
    "    image1, image2, label = get_images_path_and_labels(df, 'training_img', get_label=True)\n",
    "    dataset = ( tf.data.Dataset.from_tensor_slices((image1, image2, label))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .cache()\n",
    "                 .batch(BATCH_SIZE)\n",
    "                 .prefetch(AUTO)\n",
    "              )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026657,
     "end_time": "2020-12-01T07:12:47.102835",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.076178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.166356Z",
     "iopub.status.busy": "2020-12-01T07:12:47.165213Z",
     "iopub.status.idle": "2020-12-01T07:12:47.168880Z",
     "shell.execute_reply": "2020-12-01T07:12:47.168178Z"
    },
    "papermill": {
     "duration": 0.039072,
     "end_time": "2020-12-01T07:12:47.169046",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.129974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, df, learning_rate_scheduler):\n",
    "    \n",
    "    # copy the training set\n",
    "    train = df.copy()\n",
    "    \n",
    "#     # apply label smoothing\n",
    "#     # Perform label smoothing; change label 1 to 0.9, and label 0 to 0.1\n",
    "#     train.iloc[:,-1] = train.iloc[:,-1].apply(lambda x: (1-COEF_SMOOTHING) if x == 1 else (COEF_SMOOTHING))\n",
    "    \n",
    "#     # get samples in training data that have the same image and labelled 1 -> assign label to 1\n",
    "#     # the idea is to make sure the model confident with these samples are similar\n",
    "#     identic_img_idx = train.loc[(train.image_1 == train.image_2) & (train.Label == 0.9)].index\n",
    "#     train.loc[identic_img_idx, 'Label'] = 1\n",
    "#     # get samples in training data that have the same title and labelled 1 -> assign label to 1\n",
    "#     identic_txt_idx = train.loc[(train.title_1 == train.title_2) & (train.Label == 0.9)].index\n",
    "#     train.loc[identic_txt_idx, 'Label'] = 1\n",
    "    \n",
    "#     print(\"Identic Image with Label 1 :\", len(identic_img_idx))\n",
    "#     print(\"Identic Title with Label 1 :\", len(identic_txt_idx))\n",
    "    print(\"Training data shape :\", train.shape)\n",
    "    \n",
    "    # Get TF Dataset\n",
    "    train_dataset = get_training_dataset(train)\n",
    "    \n",
    "    model = get_model()\n",
    "    history = model.fit(train_dataset, steps_per_epoch = len(train.Label) // BATCH_SIZE,\n",
    "                        callbacks = [learning_rate_scheduler],\n",
    "                        epochs = EPOCH\n",
    "                       )\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.228975Z",
     "iopub.status.busy": "2020-12-01T07:12:47.228203Z",
     "iopub.status.idle": "2020-12-01T07:12:47.231949Z",
     "shell.execute_reply": "2020-12-01T07:12:47.231305Z"
    },
    "papermill": {
     "duration": 0.035712,
     "end_time": "2020-12-01T07:12:47.232071",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.196359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Perform Training Model\n",
    "\n",
    "# # Define model\n",
    "# model = get_model()\n",
    "\n",
    "# # Define learning rate scheduler\n",
    "# learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_function, verbose = True)\n",
    "\n",
    "# # Get traning data\n",
    "# GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"pre-product-matching-id-ndsc-2020\")\n",
    "# train = pd.read_csv(\"../input/pre-product-matching-id-ndsc-2020/new_training_set.csv\").iloc[:, 1:]\n",
    "\n",
    "# # Perform training\n",
    "# model, history = train_model(model, train, learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.292216Z",
     "iopub.status.busy": "2020-12-01T07:12:47.291382Z",
     "iopub.status.idle": "2020-12-01T07:12:47.295133Z",
     "shell.execute_reply": "2020-12-01T07:12:47.294336Z"
    },
    "papermill": {
     "duration": 0.035847,
     "end_time": "2020-12-01T07:12:47.295261",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.259414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Print Model Summary\n",
    "# model.summary()\n",
    "\n",
    "# # Save model\n",
    "# model_name = \"Xception\" + \"_\" + str(BATCH_SIZE) + \"_\" + str(EMBEDDING_SIZE) + \"_\" + str(EPOCH) + \"_\" + str(LR_START) + \"_\" + 'BinaryCrossEntropy' + \".h5\"\n",
    "# print(model_name)\n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.356264Z",
     "iopub.status.busy": "2020-12-01T07:12:47.355139Z",
     "iopub.status.idle": "2020-12-01T07:12:47.358387Z",
     "shell.execute_reply": "2020-12-01T07:12:47.357664Z"
    },
    "papermill": {
     "duration": 0.035499,
     "end_time": "2020-12-01T07:12:47.358530",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.323031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Plot History\n",
    "# history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# # Plot loss, accuracy, and f1 score\n",
    "# history_df['loss'].plot()\n",
    "# history_df['acc'].plot()\n",
    "# history_df['f1_m'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027718,
     "end_time": "2020-12-01T07:12:47.414140",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.386422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read Model and Optimize Cut-off Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.477062Z",
     "iopub.status.busy": "2020-12-01T07:12:47.476131Z",
     "iopub.status.idle": "2020-12-01T07:12:47.478839Z",
     "shell.execute_reply": "2020-12-01T07:12:47.479401Z"
    },
    "papermill": {
     "duration": 0.037963,
     "end_time": "2020-12-01T07:12:47.479590",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.441627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Kaggle Dataset, get model and y_probas\n",
    "import joblib\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "\n",
    "# get probabilities from Cross Validation\n",
    "\n",
    "# Xception 400\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_xception400.pkl\")\n",
    "\n",
    "# # DenseNet201 128, Manual Label Smoothing\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_densenet128.pkl\")\n",
    "\n",
    "# # DenseNet201 128, Non Manual Label Smoothing\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_densenet128_nonmanuallabeling.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.550370Z",
     "iopub.status.busy": "2020-12-01T07:12:47.545034Z",
     "iopub.status.idle": "2020-12-01T07:12:47.568061Z",
     "shell.execute_reply": "2020-12-01T07:12:47.567329Z"
    },
    "papermill": {
     "duration": 0.060128,
     "end_time": "2020-12-01T07:12:47.568188",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.508060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimize cut off / threshold\n",
    "def get_best_threshold(fpr, tpr, thresholds):\n",
    "    # threshold based on min absolute difference of sen and spec\n",
    "    diff = np.abs(tpr - (1-fpr))\n",
    "    idx = np.where(diff == min(diff))[0][0]\n",
    "    cut_min = thresholds[idx]\n",
    "    \n",
    "    # threshold based on youden index    \n",
    "    diff = tpr + (1-fpr) - 1\n",
    "    idx = np.where (diff == max(diff))[0][0]\n",
    "    cut_youden = thresholds[idx]\n",
    "    \n",
    "    # threshold based on highest average of sensitivity and specisficity\n",
    "    diff = (tpr + (1-fpr)) / 2\n",
    "    idx = np.where (diff == max(diff))[0][0]\n",
    "    cut_avg = thresholds[idx]\n",
    "    \n",
    "    # threshold based on min euclidian distance in ROC curve\n",
    "    diff = np.sqrt(fpr**2 + (1-tpr)**2)\n",
    "    idx = np.where (diff == min(diff))[0][0]\n",
    "    cut_euclid = thresholds[idx]\n",
    "    \n",
    "    return cut_min, cut_youden, cut_avg, cut_euclid\n",
    "\n",
    "def get_avg_best_threshold(y_vals, y_probas):\n",
    "    mins = []\n",
    "    youdens = []\n",
    "    avgs = []\n",
    "    euclids = []\n",
    "    \n",
    "    for i in range(len(y_vals)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_vals[i], y_probas[i])\n",
    "        cut_min, cut_youden, cut_avg, cut_euclid = get_best_threshold(fpr, tpr, thresholds)\n",
    "        mins.append(cut_min)\n",
    "        youdens.append(cut_youden)\n",
    "        avgs.append(cut_avg)\n",
    "        euclids.append(cut_euclid)\n",
    "        print(\"Fold \", i)\n",
    "        print(\"Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\")\n",
    "        print(cut_min, cut_youden, cut_avg, cut_euclid)\n",
    "    \n",
    "    print(\"Average all folds\")\n",
    "    print(\"Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\")\n",
    "    print(np.mean(mins), np.mean(youdens), np.mean(avgs), np.mean(euclids))\n",
    "    cut_min, cut_youden, cut_avg, cut_euclid = np.mean(mins), np.mean(youdens), np.mean(avgs), np.mean(euclids)\n",
    "    averaged_threshold = np.mean([cut_min, cut_youden, cut_avg, cut_euclid])\n",
    "    print(\"FINAL THRESHOLD \", averaged_threshold)\n",
    "    return averaged_threshold\n",
    "\n",
    "def evaluate_thresholds(y_vals, y_probas, best_threshold):\n",
    "    f1s = []\n",
    "    for i in range(len(y_vals)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_vals[i], y_probas[i])\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        y_pred = np.where(y_probas[i] >= best_threshold, 1, 0)\n",
    "        f1 = f1_score(y_vals[i], y_pred)\n",
    "        f1s.append(f1)\n",
    "        print(\"Fold \", i)\n",
    "        print(\"ROC AUC | F1 \")\n",
    "        print(auc_score, f1)\n",
    "    print(\"F1 mean :\", np.mean(f1s), \", std: \", np.std(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.631163Z",
     "iopub.status.busy": "2020-12-01T07:12:47.630086Z",
     "iopub.status.idle": "2020-12-01T07:12:47.632864Z",
     "shell.execute_reply": "2020-12-01T07:12:47.633401Z"
    },
    "papermill": {
     "duration": 0.036699,
     "end_time": "2020-12-01T07:12:47.633589",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.596890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate and get best threshold\n",
    "\n",
    "# # Xception 400\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_xception400.pkl\")\n",
    "\n",
    "# y_probas = probas_vals[0]\n",
    "# y_vals = probas_vals[1]\n",
    "\n",
    "# best_threshold = get_avg_best_threshold(y_vals, y_probas)\n",
    "# evaluate_thresholds(y_vals, y_probas, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.696316Z",
     "iopub.status.busy": "2020-12-01T07:12:47.695332Z",
     "iopub.status.idle": "2020-12-01T07:12:47.698669Z",
     "shell.execute_reply": "2020-12-01T07:12:47.697985Z"
    },
    "papermill": {
     "duration": 0.036637,
     "end_time": "2020-12-01T07:12:47.698805",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.662168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate and get best threshold\n",
    "# # DenseNet201 128, Manual Label Smoothing\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_densenet128.pkl\")\n",
    "\n",
    "# y_probas = probas_vals[0]\n",
    "# y_vals = probas_vals[1]\n",
    "\n",
    "# best_threshold = get_avg_best_threshold(y_vals, y_probas)\n",
    "# evaluate_thresholds(y_vals, y_probas, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.761290Z",
     "iopub.status.busy": "2020-12-01T07:12:47.760389Z",
     "iopub.status.idle": "2020-12-01T07:12:47.763693Z",
     "shell.execute_reply": "2020-12-01T07:12:47.763031Z"
    },
    "papermill": {
     "duration": 0.03651,
     "end_time": "2020-12-01T07:12:47.763830",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.727320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate and get best threshold\n",
    "\n",
    "# # # DenseNet201 128, Non Manual Label Smoothing\n",
    "# probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_densenet128_nonmanuallabeling.pkl\")\n",
    "\n",
    "# y_probas = probas_vals[0]\n",
    "# y_vals = probas_vals[1]\n",
    "\n",
    "# best_threshold = get_avg_best_threshold(y_vals, y_probas)\n",
    "# evaluate_thresholds(y_vals, y_probas, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:47.828061Z",
     "iopub.status.busy": "2020-12-01T07:12:47.827134Z",
     "iopub.status.idle": "2020-12-01T07:12:47.881274Z",
     "shell.execute_reply": "2020-12-01T07:12:47.880505Z"
    },
    "papermill": {
     "duration": 0.088795,
     "end_time": "2020-12-01T07:12:47.881399",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.792604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\n",
      "0.16996369 0.30516595 0.30516595 0.28864905\n",
      "Fold  1\n",
      "Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\n",
      "0.64035034 0.78223264 0.78223264 0.6937445\n",
      "Fold  2\n",
      "Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\n",
      "0.56644654 0.6728268 0.6728268 0.5633914\n",
      "Fold  3\n",
      "Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\n",
      "0.57972807 0.5965923 0.5965923 0.5965923\n",
      "Average all folds\n",
      "Min Abs Diff | Youden Idx | Highest Avg | Euclid Distance\n",
      "0.48912215 0.58920443 0.58920443 0.53559434\n",
      "FINAL THRESHOLD  0.55078137\n",
      "Fold  0\n",
      "ROC AUC | F1 \n",
      "0.9297384847825333 0.844715757344525\n",
      "Fold  1\n",
      "ROC AUC | F1 \n",
      "0.916684977938075 0.8554012868269556\n",
      "Fold  2\n",
      "ROC AUC | F1 \n",
      "0.935221035988594 0.8812737971616476\n",
      "Fold  3\n",
      "ROC AUC | F1 \n",
      "0.9398900944861606 0.8860585197934596\n",
      "F1 mean : 0.866862340281647 , std:  0.017306142546332847\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and get best threshold\n",
    "\n",
    "# # DenseNet201 128, Non Manual Label Smoothing + Distance embedding\n",
    "probas_vals = joblib.load(\"../input/shopeeproductmatching/probas_vals_densenet_distance.pkl\")\n",
    "\n",
    "y_probas = probas_vals[0]\n",
    "y_vals = probas_vals[1]\n",
    "\n",
    "best_threshold = get_avg_best_threshold(y_vals, y_probas)\n",
    "evaluate_thresholds(y_vals, y_probas, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028809,
     "end_time": "2020-12-01T07:12:47.939662",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.910853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get The Model from previous Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:12:48.014438Z",
     "iopub.status.busy": "2020-12-01T07:12:48.013507Z",
     "iopub.status.idle": "2020-12-01T07:13:28.189892Z",
     "shell.execute_reply": "2020-12-01T07:13:28.190485Z"
    },
    "papermill": {
     "duration": 40.215312,
     "end_time": "2020-12-01T07:13:28.190716",
     "exception": false,
     "start_time": "2020-12-01T07:12:47.975404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2, 299, 299, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 299, 299, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 299, 299, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "densenet201 (Model)             (None, 9, 9, 1920)   18321984    lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 1920)         0           densenet201[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 1920)         0           densenet201[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1920)         0           densenet201[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1920)         0           densenet201[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6)            0           lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            7           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 18,321,991\n",
      "Trainable params: 18,092,935\n",
      "Non-trainable params: 229,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# # DenseNet201 128, Non Manual Label Smoothing\n",
    "\n",
    "configs = {'DIM': DIM, 'f1_m': f1_m}\n",
    "model_path = \"../input/shopeeproductmatching/DenseNet201_Distance_Cosine_Manhattan_NegExpManhattan_64_128_30_1e-05_BinaryCrossEntropy.h5\"\n",
    "\n",
    "model = load_model(model_path, configs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029444,
     "end_time": "2020-12-01T07:13:28.250234",
     "exception": false,
     "start_time": "2020-12-01T07:13:28.220790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:13:28.327773Z",
     "iopub.status.busy": "2020-12-01T07:13:28.326910Z",
     "iopub.status.idle": "2020-12-01T07:13:29.571660Z",
     "shell.execute_reply": "2020-12-01T07:13:29.571008Z"
    },
    "papermill": {
     "duration": 1.291526,
     "end_time": "2020-12-01T07:13:29.571804",
     "exception": false,
     "start_time": "2020-12-01T07:13:28.280278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Prepare Test Set\n",
    "\n",
    "# path\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"product-matching-id-ndsc-2020\")\n",
    "SUBFOLDER = 'test_img'\n",
    "\n",
    "# read test file\n",
    "test = pd.read_csv(\"../input/product-matching-id-ndsc-2020/new_test_set.csv\").iloc[:,1:]\n",
    "\n",
    "# perform\n",
    "test_safe = test.iloc[0:19008,:]\n",
    "\n",
    "# get image paths\n",
    "test_im1, test_im2, dummy_label = get_images_path_and_labels(test_safe, SUBFOLDER, get_label=False)\n",
    "\n",
    "# Create TF Dataset for test set\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_im1, test_im2, dummy_label))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .batch(BATCH_SIZE)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:13:29.640619Z",
     "iopub.status.busy": "2020-12-01T07:13:29.639593Z",
     "iopub.status.idle": "2020-12-01T07:35:42.368599Z",
     "shell.execute_reply": "2020-12-01T07:35:42.365988Z"
    },
    "papermill": {
     "duration": 1332.766563,
     "end_time": "2020-12-01T07:35:42.368770",
     "exception": false,
     "start_time": "2020-12-01T07:13:29.602207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform Scoring\n",
      "297/297 [==============================] - 1317s 4s/step\n",
      "Complete Scoring\n",
      "(19008, 1)\n"
     ]
    }
   ],
   "source": [
    "# Perform Prediction\n",
    "print(\"Perform Scoring\")\n",
    "y_proba1 = model.predict(test_dataset, verbose=1)\n",
    "\n",
    "print(\"Complete Scoring\")\n",
    "print(y_proba1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:35:42.681205Z",
     "iopub.status.busy": "2020-12-01T07:35:42.680123Z",
     "iopub.status.idle": "2020-12-01T07:35:42.685427Z",
     "shell.execute_reply": "2020-12-01T07:35:42.684672Z"
    },
    "papermill": {
     "duration": 0.164825,
     "end_time": "2020-12-01T07:35:42.685557",
     "exception": false,
     "start_time": "2020-12-01T07:35:42.520732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape : (19008, 1)\n",
      "prediction proportion : 0.493108164983165\n"
     ]
    }
   ],
   "source": [
    "# Perform cut-off\n",
    "\n",
    "y_pred = np.where(y_proba1 >= best_threshold, 1, 0)\n",
    "\n",
    "print(\"prediction shape :\", y_pred.shape)\n",
    "print(\"prediction proportion :\", y_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:35:43.013329Z",
     "iopub.status.busy": "2020-12-01T07:35:43.012439Z",
     "iopub.status.idle": "2020-12-01T07:35:43.214235Z",
     "shell.execute_reply": "2020-12-01T07:35:43.214884Z"
    },
    "papermill": {
     "duration": 0.378408,
     "end_time": "2020-12-01T07:35:43.215062",
     "exception": false,
     "start_time": "2020-12-01T07:35:42.836654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_1</th>\n",
       "      <th>image_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>image_2</th>\n",
       "      <th>pair_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Celana Chino Panjang Original Motz</td>\n",
       "      <td>6985a78ebd6b7d9f120f852b412bba5b.jpg</td>\n",
       "      <td>Celana Chino Panjang Original Motz</td>\n",
       "      <td>81f8fab965d009483d004af0c697dd97.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BISA COD] Tas LOL Boneka Flash Anak Ransel</td>\n",
       "      <td>4d6f929847cbe632b15baa556646a414.jpg</td>\n",
       "      <td>Bisa Cod Tas Lol Boneka Mewah Anak Ransel Tas ...</td>\n",
       "      <td>1e2facde94db9de3037741ec4a5313c8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOYO AJAIB KINOKI GOLD paket Standard</td>\n",
       "      <td>e21056441f03442737a2c074a4ab232d.jpg</td>\n",
       "      <td>BL - V.PJG Baju Kaos Vneck Polos Lengan Panjan...</td>\n",
       "      <td>7b91ab6c71c6e9ed432201f12379509c.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zwitsal Natural Aloe Vera Baby Bath 2 In 1 Hai...</td>\n",
       "      <td>3ac880adf8ffbcf23846554efc052694.jpg</td>\n",
       "      <td>ZWITSAL Natural Baby Bath 2 in 1 Hair &amp; Body b...</td>\n",
       "      <td>46b00a7c6a869e00cad8cc08fb56a2f7.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAS IMPORT JAKARTA CLASSIC DIAMOND JELLY MATTE...</td>\n",
       "      <td>4ddd79c9d601bd25c1a56e0a10fb5708.jpg</td>\n",
       "      <td>TAS IMPORT JAKARTA CLASSIC DIAMOND JELLY MATTE...</td>\n",
       "      <td>10a97ae389e298f72bc455aa4cb4fba7.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_1  \\\n",
       "0                 Celana Chino Panjang Original Motz   \n",
       "1        [BISA COD] Tas LOL Boneka Flash Anak Ransel   \n",
       "2              KOYO AJAIB KINOKI GOLD paket Standard   \n",
       "3  Zwitsal Natural Aloe Vera Baby Bath 2 In 1 Hai...   \n",
       "4  TAS IMPORT JAKARTA CLASSIC DIAMOND JELLY MATTE...   \n",
       "\n",
       "                                image_1  \\\n",
       "0  6985a78ebd6b7d9f120f852b412bba5b.jpg   \n",
       "1  4d6f929847cbe632b15baa556646a414.jpg   \n",
       "2  e21056441f03442737a2c074a4ab232d.jpg   \n",
       "3  3ac880adf8ffbcf23846554efc052694.jpg   \n",
       "4  4ddd79c9d601bd25c1a56e0a10fb5708.jpg   \n",
       "\n",
       "                                             title_2  \\\n",
       "0                 Celana Chino Panjang Original Motz   \n",
       "1  Bisa Cod Tas Lol Boneka Mewah Anak Ransel Tas ...   \n",
       "2  BL - V.PJG Baju Kaos Vneck Polos Lengan Panjan...   \n",
       "3  ZWITSAL Natural Baby Bath 2 in 1 Hair & Body b...   \n",
       "4  TAS IMPORT JAKARTA CLASSIC DIAMOND JELLY MATTE...   \n",
       "\n",
       "                                image_2  pair_index  label  \n",
       "0  81f8fab965d009483d004af0c697dd97.jpg           0      0  \n",
       "1  1e2facde94db9de3037741ec4a5313c8.jpg           1      1  \n",
       "2  7b91ab6c71c6e9ed432201f12379509c.jpg           2      0  \n",
       "3  46b00a7c6a869e00cad8cc08fb56a2f7.jpg           3      1  \n",
       "4  10a97ae389e298f72bc455aa4cb4fba7.jpg           4      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe\n",
    "test['pair_index'] = test.index\n",
    "test['label'] = 1\n",
    "test.iloc[0:19008,-1] = y_pred\n",
    "test[['pair_index', 'label']].to_csv(\"submission1.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:35:43.564105Z",
     "iopub.status.busy": "2020-12-01T07:35:43.538368Z",
     "iopub.status.idle": "2020-12-01T07:35:43.803487Z",
     "shell.execute_reply": "2020-12-01T07:35:43.802670Z"
    },
    "papermill": {
     "duration": 0.436262,
     "end_time": "2020-12-01T07:35:43.803641",
     "exception": false,
     "start_time": "2020-12-01T07:35:43.367379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform\n",
    "test_safe2 = test.iloc[19070:,:]\n",
    "\n",
    "# get image paths\n",
    "test_im1, test_im2, dummy_label = get_images_path_and_labels(test_safe2, SUBFOLDER, get_label=False)\n",
    "\n",
    "# Create TF Dataset for test set\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices((test_im1, test_im2, dummy_label))\n",
    "                 .map(decode_image, num_parallel_calls=AUTO)\n",
    "                 .batch(BATCH_SIZE)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:35:44.120242Z",
     "iopub.status.busy": "2020-12-01T07:35:44.119266Z",
     "iopub.status.idle": "2020-12-01T07:51:12.067512Z",
     "shell.execute_reply": "2020-12-01T07:51:12.066619Z"
    },
    "papermill": {
     "duration": 928.110686,
     "end_time": "2020-12-01T07:51:12.067719",
     "exception": false,
     "start_time": "2020-12-01T07:35:43.957033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform Scoring\n",
      "212/212 [==============================] - 920s 4s/step\n",
      "Complete Scoring\n",
      "(13510, 1)\n"
     ]
    }
   ],
   "source": [
    "# Perform Prediction\n",
    "print(\"Perform Scoring\")\n",
    "y_proba2 = model.predict(test_dataset, verbose=1)\n",
    "\n",
    "print(\"Complete Scoring\")\n",
    "print(y_proba2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:51:12.548390Z",
     "iopub.status.busy": "2020-12-01T07:51:12.547432Z",
     "iopub.status.idle": "2020-12-01T07:51:12.552936Z",
     "shell.execute_reply": "2020-12-01T07:51:12.552170Z"
    },
    "papermill": {
     "duration": 0.248753,
     "end_time": "2020-12-01T07:51:12.553073",
     "exception": false,
     "start_time": "2020-12-01T07:51:12.304320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape : (13510, 1)\n",
      "prediction proportion : 0.49844559585492226\n"
     ]
    }
   ],
   "source": [
    "# Perform cut-off\n",
    "\n",
    "y_pred = np.where(y_proba2 >= best_threshold, 1, 0)\n",
    "\n",
    "print(\"prediction shape :\", y_pred.shape)\n",
    "print(\"prediction proportion :\", y_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-01T07:51:13.042684Z",
     "iopub.status.busy": "2020-12-01T07:51:13.029338Z",
     "iopub.status.idle": "2020-12-01T07:51:13.126222Z",
     "shell.execute_reply": "2020-12-01T07:51:13.125517Z"
    },
    "papermill": {
     "duration": 0.337528,
     "end_time": "2020-12-01T07:51:13.126355",
     "exception": false,
     "start_time": "2020-12-01T07:51:12.788827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive proportion : 0.4962860650705955\n",
      "File submission save\n"
     ]
    }
   ],
   "source": [
    "# Save the result for submission\n",
    "\n",
    "# # create test dataframe\n",
    "# test['label'] = y_pred\n",
    "# test['pair_index'] = test.index\n",
    "# test.head()\n",
    "\n",
    "test.iloc[19070:,-1] = y_pred\n",
    "\n",
    "# save as csv\n",
    "test[['pair_index', 'label']].to_csv(\"submission2.csv\", index=False)\n",
    "print(\"Positive proportion :\", test.label.mean())\n",
    "print(\"File submission save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2325.047238,
   "end_time": "2020-12-01T07:51:13.470248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-01T07:12:28.423010",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
